{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:36:26.103374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 14:36:26.766809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 15:03:03.179440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-13 15:03:03.179969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-13 15:03:35.940519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-13 15:03:35.941222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-06-13 15:03:36.687084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-06-13 15:03:36.687501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/tr_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples, test_examples = examples['train'], examples['validation'], examples['test']\n",
    "\n",
    "#save dataset to csv\n",
    "def save_to_csv(dataset, filename):\n",
    "      with open(filename, 'a+') as f:\n",
    "         for pt, en in tfds.as_numpy(dataset):\n",
    "               f.write(str(pt, 'utf-8') + \"<DELIM>\" + str(en, 'utf-8') + \"\\n\")\n",
    "\n",
    "#save training, validation and test to one csv file\n",
    "save_to_csv(train_examples, 'data.csv')\n",
    "save_to_csv(val_examples, 'data.csv')\n",
    "save_to_csv(test_examples, 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15079/3382394657.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data_df = pd.read_csv('data.csv', names=['tr', 'en'], sep='<DELIM>')\n",
      "/tmp/ipykernel_15079/3382394657.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv('train.csv', names=['tr', 'en'], sep='<DELIM>')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  383048\n",
      "Number of samples 182450\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.read_csv('data.csv', names=['tr', 'en'], sep='<DELIM>')\n",
    "train_df = pd.read_csv('train.csv', names=['tr', 'en'], sep='<DELIM>')\n",
    "val_df = pd.read_csv('val.csv', names=['tr', 'en'], sep='<DELIM>')\n",
    "test_df = pd.read_csv('test.csv', names=['tr', 'en'], sep='<DELIM>')\n",
    "\n",
    "#print number of samples in each dataset\n",
    "print('Number of training samples: ', len(data_df[data_df['tr'].notna()]))\n",
    "print('Number of samples', len(train_df[train_df['tr'].notna()]))\n",
    "print('Number of samples', len(val_df[val_df['tr'].notna()]))\n",
    "print('Number of samples', len(test_df[test_df['tr'].notna()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tr  \\\n",
      "0  emekli üyeler kongre'nin şu sıralar çete savaş...   \n",
      "1  entellektüellik , klas , asalet veya hikaye il...   \n",
      "2  hangisi olduğunu tahmin edebildiniz mi ? şirke...   \n",
      "3  pek uzak yerlere seyahat edemez veya belli bir...   \n",
      "4                                 heyecanlanmıştım .   \n",
      "\n",
      "                                                  en  \n",
      "0  retiring members nowadays say that it 's becom...  \n",
      "1  no sophistication , no class , no dignity , no...  \n",
      "2                     did you guess it ? companies .  \n",
      "3  you ca n't travel very far or venture too far ...  \n",
      "4                                    i was excited .  \n",
      "myriad did n't even argue this , so it came out of the blue .\n",
      "myriad bunu hiç savunmamıştı bile .\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "# print(train_df[\"tr\"][0])\n",
    "# print(train_df[\"en\"][0])\n",
    "print(test_df[\"en\"][0])\n",
    "print(test_df[\"tr\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Turkish:\n",
      "emekli üyeler kongre'nin şu sıralar çete savaşlarına döndüğünü söylüyorlar .\n",
      "entellektüellik , klas , asalet veya hikaye ile ilgisi yok ,\n",
      "hangisi olduğunu tahmin edebildiniz mi ? şirketler .\n",
      "\n",
      "> Examples in English:\n",
      "retiring members nowadays say that it 's become like gang warfare .\n",
      "no sophistication , no class , no dignity , no history .\n",
      "did you guess it ? companies .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 15:50:33.990539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-12 15:50:33.991384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-12 15:50:34.039198: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# testing if the dataset is loaded correctly\n",
    "for tr_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Turkish:')\n",
    "  for tr in tr_examples.numpy():\n",
    "    print(tr.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "bert_tokenizer_params=dict(lower_case=True)\n",
    "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    "\n",
    "bert_vocab_args = dict(\n",
    "    # Reserved tokens that must be included in the vocabulary\n",
    "    reserved_tokens=reserved_tokens,\n",
    "    # Arguments for `text.BertTokenizer`\n",
    "    bert_tokenizer_params=bert_tokenizer_params,\n",
    "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
    "    learn_params={},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
